[TOC]

---

# 基于闪存设备的事务机制研究



## 名词解释

WAL，Write Ahead Logging，预写日志系统，一种高效的日志算法。

COW，copy on write，写时复制。

JFFS，Journalling  Flash File System，闪存设备日志型文件系统。其目的是作为嵌入式系统免受宕机和断电危害的文件系统。然而用于NAND设备上JFFS已被JFFS2大量取代。

YAFFS，是第一个专门为NAND Flash存储器设计的嵌入式文件系统，适用于大容量的存储设备；并且是在GPL协议下发布的，可在其网站免费获得源代码。

FTL，Flash translation layer，FTL是一种软件中间层，用于将闪存模拟成为虚拟块设备，从而能够在闪存上实现FAT等等块设备类文件系统。FTL包含了地址映射，垃圾回收，损耗均衡等等几个方面的内容。



----

## 摘要

### QUESTION

- 传统磁盘采用写时复制策略实现事务机制，事务操作性能变差。
- 闪存的异地更新策略及良好的随机读性能，能有效支持事务机制，但现有的SSD内部嵌入式事务协议存在***事务跟踪管理开销大，恢复时间长***  的问题

### TOPIC

***提出一种基于非易失性缓存的 SSD 嵌入式事务提交协议，将事务从应用层下移至硬件层，减少上层系统复杂性极其冗余工作，提高系统可靠性。在 Linux 通用块设备层设计了一种基于闪存的通用事务协议。***

### GOALS  & OPTIONS 

- 事务跟踪管理开销小

- 与事务中止比率无关

- 快速系统恢复

- 保证垃圾回收机制的开销比较小

  ​

- NVCTX： 

- 缓存动态分配策略

- 混合存储

- TxFlashLog：

- 重新设计数据存储方式

- 通用性、移植性

----

## 一、绪论

### 背景

- IO处理能力成为计算机系统的性能瓶颈，急需解决
- 传统磁盘存储系统虽然努力解决该问题，但效果不好，同时带来了很多问题
- 同时，闪存技术兴起，SSD相对传统磁盘具有各方面的优势

### 研究意义

- 文件系统、数据库系统的事务机制存在问题。1）本身设计bug导致数据不一致。2）各层冗余工作。3）可供应用层使用的接口有限
- 解决方案：在存储层提供事务接口。
- 已有研究：在磁盘上实现存储层的事务接口，但同样存在问题（磁盘碎片、寻道、高消耗的垃圾回收）。
- 故：闪存上实现存储层的事务接口可取，有4大优势。1）闪存本身需要擦除再写入，故异地更新能保留新旧两份数据，相对日志方式，写入量减半。2）闪存随机读写性能解决了空间碎片问题。3）闪存的并行性能好提高了内部带宽。4）闪存作为新事务，具有重新提供接口规范的可能性。

### 国内研究现状

（1）支持文件系统恢复的原子写：介绍。

（2）SSD 内部支持的事务恢复机制：各事务恢复机制的实现介绍。

### 课题研究内容

- 闪存结构、闪存转换层作用、概述事务机制、分析现有的基于闪存的事务提交协议的不足
- 针对现有研究不能同时满足系统性能和快速恢复并存的状况，在 SSD 内部设计了嵌入式事务提交协议 NVCTX。充分利用非易失性缓存有效地保证了事务元数据和映射表的持久化。
- 针对现有研究通用性差，设计了一种基于闪存的通用事务机制TxFlashCache
- 实验评估：NVCTX vs WAL & TxFlash，TxFlashCache vs FlashCache

----

## 二、固态硬盘关键技术及事务机制简介

### 固态硬盘

固态硬盘，SSD，Solid State Drive。

组成：Host Interconnect、Host Interface Logic 、 Processor  、 Buffer Manager 、DRAM 、Flash Multiplexer、Flash Memory

### NAND闪存

NAND闪存：物理结构、工作原理。

- 根据单个存储单元可存储信息的比特数分为SLC、MLC、TLC。


- 组织结构：Page（页，读写基本单位，数据区+带外区OOB，out-of-band，存储管理数据，如纠错码） >   Block（块，基本擦除单位）> 闪存颗粒。

### FTL

FTL：闪存转换层工作由闪存控制器完成。主要任务有：地址映射、垃圾回收、磨损均衡。主要负责将逻辑地址转变为闪存的物理地址。相当于屏蔽磁盘和SSD的差异，兼容上层系统的工作方式（在LBA上进行IO操作）。

- 地址映射：兼容磁盘读写单位512字节扇区和闪存读写单位页大小可变通常为几KB。文件系统 > 逻辑扇区地址LSA > 逻辑页地址LPA > 映射关系得物理页地址PPA。FTL的地址映射主要为LPA和PPA的映射关系。另一个工作就是管理因为“异地写“而出现的动态PPA问题。
- 垃圾回收：前台GC，后台GC。寻找GC块（常用贪心算法）、判断GC块数据是否有有效数据、擦除GC块。
- 磨损均衡（wear leveling）：闪存的每个块PE次数有限，通过算法保准尽可能让每个块的写入（擦除）次数均衡。产生块使用不均的主要原因是冷（常读，不常修改，多媒体文件）热（常修改，log文件）数据分布不均。

### 事务

- 事务：事务是一组操作序列。这些操作要么全做，要么全都不做。这些操作序列组成一个不可分割的工作单元。一个逻辑工作单元要成为事务，必须具备下四个属性（ACID）：原子性（Atomicty）、一致性(Consistency)、隔离性(Isolation)和永久性(Durability)。
- 事务恢复技术：Redo 操作将已完成事务缓存在缓冲区的数据重新写到非易失性存储设备上。Undo 操作将未完成的事务，但是部分数据已更新到存储设备，在系统重启时，撤销未完成事务对数据库系统或文件系统的修改，回滚到一个一致性状态。
  - WAL，write ahead log，预写式日志技术，先将事务对数据的修改先以日志记录的格式顺序追加写在日志区域。日志区域到达一个阈值时，WAL执行checkpoint操作，将日志区数据写入数据区，利用日志区可以进行恢复。
  - SP，shadow page，影子页技术，系统为需要修改的页分配一个影子页，在影子页上进行数据操作。


---

## 三、基于有限非易失性缓存 SSD 的事务协议设计与实现

### 设计动机

现有的SSD内部嵌入式事务提交协议存在三个问题：1）代价高。2）性能受限于高的事务终止比率。3）系统故障后的恢复时间较长。

提出NVCTX协议完成将磁盘缓存中的数据在断电等异常情况下保存下来。

### NVCTX概述

NVCTX的核心思想是利用NVM-Cache跟踪事务的状态，保持最新的有效的地址映射表。在原有的FTL模块上增加了事
务提交逻辑、系统恢复逻辑、In-Process 表、NVM 映射表四个功能模块。

### NVCTX接口

NVCTX协议是在原FTL层功能之上扩展功能及其相应的接口工作的。

| 接口                       |                 功能                 |
| ------------------------ | :--------------------------------: |
| WRITE(Lba, Len)          |        正常写长度为 Len 的数据到 Lba         |
| READ (Lba, Len)          |        从 Lba 处读长度为 len 的数据         |
| TX_WRITE(TxId, Lba, Len) | 事务编号为 TxId 的事务写请求写长度为 Len 的数据到 Lba |
| TX_START(TxId)           |       核查事务编号 TxId 的有效性，并开始事务       |
| TX_COMMIT(TxId)          |          提交事务编号为 TxId 的事务          |
| TX_ABORT(TxId)           |          中止事务编号为 TxId 的事务          |

### NVCTX事务流程

略

### 动态分配算法

NVM-Cache是部分DRAM空间，是需要在断电情况下利用辅助供电设备持久化的部分，所以空间有限，NVM-Cache用于存储两张数据表，In-Process表和NVM映射表，而In-Process是根据事务请求负载动态变化。故设计该动态分配算法为NVM-Cache分配空间。

算法过程：***没看懂***……`// TODO`

### 混合存储

根据前文知In-Process表大小有限，针对在允许的最大空间条件下，仍然不能存储当前所有的事务元数据，设计一种混合存储的策略来存储事务元数据。

混合存储方法通过 NVM-Cache 结合闪存来保存事务的元数据，NVM-Cache 保存事务的状态、事务号、事务链表指针以及部分事务页面写请求映射表元数据，闪存中保存另一部分事务页面请求元数据。

### 系统恢复

因为系统异常时，事务元数据由NVM-Cache写入SPO，故只需逆向遍历SPO区域而不用重新扫描整个SSD，大大减少系统恢复时间。

### 实验

* 事务中止率为0时的测试（性能，各负载下的吞吐量）
* 事务中止率对整个系统的影响测试（性能，耐久性（写页数作为衡量指标），GC时间）
* NVM-Cache分配影响（动态分配和静态分配的对比测试）
* 混合存储（吞吐量、耐久性）
* 恢复时间
* SSD容量影响（吞吐量，恢复时间）

### 结论

略

----

## 四、基于闪存的通用事务设计与实现

### 设计动机

1）Flash作为SSD的缓存，在Device Mapping层实现

2）已有SSD内部事务提交协议都是在FTL固件中实现，通常与特定硬件平台有关，很难实现移植。

故，本文在通用块层的Device Mapping层上实现了事务机制，使其具有通用性。

本文设计的TxFlashCache基于FlashCache框架设计实现，将数据以log-structured的方式组织，在TxFlashCache内部实现事务的原子性和持久性，更改原有的空间分配策略和垃圾回收机制。

### Device Mapper

DM是Linux内核中提供的一种从逻辑设备到物理设备的映射机制。DM 用户空间负责配置控制逻辑以及具体策略，而内核 Device Mapper 负责 bio 请求的具体过滤、bio 重组以及请求的重定向。DM机制分为两部分：1）内核Device Mapper驱动程序。2）用户空间device mapper库和它的dmsteup工具。

DM包含的三个重要对象：

- mapped device：逻辑概念，内核提供给外部的一个逻辑设备，通过映射表和target device建立映射关系。
- 映射表：一个多元组表示，包括mapped device的起始地址、范围、target类型变量以及target device物理设备的地址偏移量。
- target device：mapped device所映射的物理设备的地址空间段，或者说是mapped device所表示的逻辑设备所映射的物理设备。

target device插件与DM的这三个对象共同构成一颗可迭代的树，根节点为逻辑设备，叶子节点为物理设备。

### FlashCache

FlashCache简单说就是一个 SSD 作为机械硬盘缓存的驱动程序。其具有三种写方式：

- write back：数据先写到 SSD 缓存中，数据从 SSD 被替换出去时才写到机械硬盘中。
- write through：数据写一份到 SSD，写一份到机械硬盘，数据的可靠性非常高，但写性能降低，读性能提高。
- write around： 数据直接写到机械硬盘，只有读未命中时，才将机械硬盘数据缓存在 SSD。

FlashCache分为4个模块：

- 调度模块：也称读写模块，在代码中对应 flashcache_map映射函数，它是 flashcache 缓存层次数据入口。接收到数据后，它会根据 bio 请求的读写类型、是否命中缓存等因素，选择不同的处理分支。
- 逻辑处理模块：也称读写后处理模块。代码中对应 flashcache_io_callback，它在调度模块通过底层存储模块执行数据读写操作完成后回调执行。
- 底层存储模块：主要提供了两种方式来完成真实的数据读写。
  - DM提供：dm_io函数 - submit_bio函数 - 通用块层 - 转发到真实的设备驱动 - 完成读写。
  - kcopyd：内核提供的底层拷贝函数，主要负责脏块写回，元数据更新。
- 后台清理模块：针对每个 set 进行数据清理，它会基于两种策略对脏块做回收。
  - 脏块超过阈值
  - 脏块超过预设的时间（fallow_delay）没有被处理

### FlashCache写处理

### FlashCache读处理

### FlashCache后台清理

FlashCache实现了LRU、FIFO替换算法，替换单位为一个缓存块，不从整个SSD寻找合适的缓存块进行替换，而是在set中寻找缓存块。

### TxFlashCache设计

SSD随机写影响SSD的性能和寿命，提出Log-structured方式将随机写转化为顺序写。

